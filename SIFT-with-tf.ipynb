{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from typing import Union, TypeVar\n",
    "from collections import namedtuple\n",
    "import cv2\n",
    "\n",
    "PI = tf.cast(\n",
    "    tf.math.angle(tf.constant(-1, dtype=tf.complex64)), tf.float32\n",
    ")\n",
    "\n",
    "KT = TypeVar('KT', bound='KeyPoints')\n",
    "unpacked_octave = namedtuple('unpacked_octave', 'octave, layer, scale')\n",
    "\n",
    "\n",
    "class Octave:\n",
    "    def __init__(\n",
    "            self,\n",
    "            index: int,\n",
    "            gss: tf.Tensor\n",
    "    ):\n",
    "        self.__shape = gss.get_shape().as_list()\n",
    "        self.index = index\n",
    "        self.gss = gss\n",
    "        self.magnitude, self.orientation = compute_mag_ori(gss)\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> list:\n",
    "        return self.__shape\n",
    "\n",
    "\n",
    "class KeyPoints:\n",
    "    def __init__(\n",
    "            self,\n",
    "            pt: Union[None, tf.Tensor] = None,\n",
    "            size: Union[None, tf.Tensor] = None,\n",
    "            angle: Union[None, tf.Tensor] = None,\n",
    "            octave: Union[None, tf.Tensor] = None,\n",
    "            response: Union[None, tf.Tensor] = None,\n",
    "            as_image_size: bool = False\n",
    "    ):\n",
    "        self.scale_index = None\n",
    "        self.__shape = (0,)\n",
    "        self.pt = tf.constant([[]], shape=(0, 3), dtype=tf.float32)\n",
    "        self.size = tf.constant([[]], shape=(0, 1), dtype=tf.float32)\n",
    "        self.angle = tf.constant([[]], shape=(0, 1), dtype=tf.float32)\n",
    "        self.octave = tf.constant([[]], shape=(0, 1), dtype=tf.float32)\n",
    "        self.response = tf.constant([[]], shape=(0, 1), dtype=tf.float32)\n",
    "        self.as_image_size = as_image_size\n",
    "        if pt is not None: self.__constructor(pt, size, angle, octave, response)\n",
    "        self.__n_batch = None\n",
    "\n",
    "    def __add__(\n",
    "            self,\n",
    "            other: KT\n",
    "    ) -> KT:\n",
    "        if not isinstance(other, KeyPoints): raise TypeError\n",
    "        if self.as_image_size ^ other.as_image_size: raise ValueError('the as_image_size parameter not inconsistent')\n",
    "        if (self.scale_index is None) ^ (other.scale_index is None):\n",
    "            if self.scale_index is None:\n",
    "                self.scale_index = tf.ones((self.shape[0], 1), tf.float32) * -1\n",
    "            else:\n",
    "                other.scale_index = tf.ones((other.shape[0], 1), tf.float32) * -1\n",
    "        ints = self.from_array(tf.concat((self.as_array(), other.as_array()), axis=0), inplace=False)\n",
    "        return ints\n",
    "\n",
    "    def __iadd__(\n",
    "            self,\n",
    "            other: KT\n",
    "    ) -> KT:\n",
    "        if not isinstance(other, KeyPoints): raise TypeError\n",
    "        if self.as_image_size ^ other.as_image_size: raise ValueError('the as_image_size parameter not inconsistent')\n",
    "        if (self.scale_index is None) ^ (other.scale_index is None):\n",
    "            if self.scale_index is None:\n",
    "                self.scale_index = tf.ones((self.shape[0], 1), tf.float32) * -1\n",
    "            else:\n",
    "                other.scale_index = tf.ones((other.shape[0], 1), tf.float32) * -1\n",
    "        self.from_array(tf.concat((self.as_array(), other.as_array()), axis=0), inplace=True)\n",
    "        return self\n",
    "\n",
    "    def __constructor(\n",
    "            self,\n",
    "            pt,\n",
    "            size,\n",
    "            angle,\n",
    "            octave,\n",
    "            response\n",
    "    ):\n",
    "        if not isinstance(pt, tf.Tensor): raise ValueError('All the fields need to be type of tf.Tensor')\n",
    "        _shape = pt.get_shape().as_list()\n",
    "        if len(_shape) > 2:\n",
    "            pt = tf.squeeze(pt)\n",
    "            _shape = pt.get_shape().as_list()\n",
    "        if len(_shape) != 2 or _shape[-1] < 3: raise ValueError(\n",
    "            'expected \"pt\" to be 2D tensor with size of (None, 3 or 4)')\n",
    "        if _shape[-1] == 4:\n",
    "            pt, scale_index = tf.split(pt, [3, 1], axis=-1)\n",
    "        else:\n",
    "            scale_index = None\n",
    "        valid = [pt]\n",
    "        for f in [size, angle, octave, response]:\n",
    "            if not isinstance(f, tf.Tensor): raise ValueError('All the fields need to be type of tf.Tensor')\n",
    "            f = tf.reshape(f, (-1, 1))\n",
    "            if f.get_shape()[0] != _shape[0]: raise ValueError('All the fields need to be with the same first dim size')\n",
    "            valid.append(f)\n",
    "        self.pt, self.size, self.angle, self.octave, self.response = valid\n",
    "        self.scale_index = scale_index\n",
    "        self.__shape = (_shape[0],)\n",
    "        self.__n_batch = None\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> tuple:\n",
    "        return self.__shape\n",
    "\n",
    "    def as_array(self) -> tf.Tensor:\n",
    "        _array = [self.pt]\n",
    "        _array += [self.scale_index] if self.scale_index is not None else []\n",
    "        _array += [self.size, self.angle, self.octave, self.response]\n",
    "        return tf.concat(_array, axis=-1)\n",
    "\n",
    "    def from_array(\n",
    "            self,\n",
    "            array:\n",
    "            tf.Tensor,\n",
    "            inplace=False\n",
    "    ) -> Union[None, KT]:\n",
    "        _shape = array.get_shape().as_list()\n",
    "        if len(_shape) != 2 or _shape[1] < 7: raise ValueError('array rank need to be 2 with size of (None, 7 or 8)')\n",
    "        splits = [4] if _shape[1] == 8 else [3]\n",
    "        splits += [1, 1, 1, 1]\n",
    "        split = tf.split(array, splits, axis=-1)\n",
    "        if not inplace: return KeyPoints(*split, as_image_size=self.as_image_size)\n",
    "        self.__constructor(*split)\n",
    "\n",
    "    def to_image_size(\n",
    "            self,\n",
    "            inplace=False\n",
    "    ) -> Union[None, KT]:\n",
    "        if self.shape[0] == 0 or self.as_image_size: return self if not inplace else None\n",
    "        pt_unpack = self.pt * tf.constant([1.0, 0.5, 0.5], dtype=tf.float32)\n",
    "        size_unpack = self.size * 0.5\n",
    "        octave_unpack = tf.cast(self.octave, dtype=tf.int64) ^ 255\n",
    "        if inplace:\n",
    "            self.pt, self.size, self.octave = pt_unpack, size_unpack, octave_unpack\n",
    "            self.as_image_size = True\n",
    "            return\n",
    "        if self.scale_index is not None: pt_unpack = tf.concat((pt_unpack, self.scale_index), -1)\n",
    "        unpack_key_points = KeyPoints(\n",
    "            pt_unpack, size_unpack, self.angle, tf.cast(octave_unpack, dtype=tf.float32), self.response, True\n",
    "        )\n",
    "        return unpack_key_points\n",
    "\n",
    "    def relies_scale_index(self):\n",
    "        self.scale_index = None\n",
    "\n",
    "    def unpack_octave(self) -> unpacked_octave:\n",
    "        if self.shape[0] == 0: return unpacked_octave(None, None, None)\n",
    "        up_key_points = self.to_image_size(inplace=False) if not self.as_image_size else self\n",
    "\n",
    "        octave_unpack = tf.cast(up_key_points.octave, tf.int64)\n",
    "        octave = octave_unpack & 255\n",
    "        octave = (octave ^ 255) - 1\n",
    "\n",
    "        layer = tf.bitwise.right_shift(octave_unpack, 8)\n",
    "        layer = layer & 255\n",
    "\n",
    "        scale = tf.where(\n",
    "            octave >= 0, tf.cast(1 / tf.bitwise.left_shift(1, octave), dtype=tf.float32),\n",
    "            tf.cast(tf.bitwise.left_shift(1, -octave), dtype=tf.float32)\n",
    "        )\n",
    "        octave = octave + 1\n",
    "        return unpacked_octave(tf.cast(octave, dtype=tf.float32), tf.cast(layer, dtype=tf.float32), scale)\n",
    "\n",
    "    def partition_by_batch(\n",
    "            self,\n",
    "            descriptors: Union[tf.Tensor, None] = None\n",
    "    ) -> tuple[list[KT], Union[tf.Tensor, None]]:\n",
    "        if self.shape[0] == 0: return None\n",
    "        part = tf.reshape(tf.cast(tf.split(self.pt, [1, 2], -1)[0], tf.int32), (-1,))\n",
    "        if descriptors is not None:\n",
    "            descriptors = tf.dynamic_partition(descriptors, part, tf.reduce_max(part) + 1)\n",
    "        part = tf.dynamic_partition(self.as_array(), part, tf.reduce_max(part) + 1)\n",
    "        out = [self.from_array(p, inplace=False) for p in part]\n",
    "        return out, descriptors\n",
    "\n",
    "    def partition_by_index(\n",
    "            self,\n",
    "            partition_index: tf.Tensor\n",
    "    ) -> list[KT]:\n",
    "        if self.shape[0] == 0: return None\n",
    "        if partition_index.get_shape()[0] != self.shape[0]:\n",
    "            raise ValueError('partition_index shape not equal to key points shape')\n",
    "        part = tf.dynamic_partition(self.as_array(), partition_index, tf.reduce_max(partition_index) + 1)\n",
    "        out = [self.from_array(p, inplace=False) for p in part]\n",
    "        return out\n",
    "\n",
    "    def n_batches(self) -> int:\n",
    "        if self.__n_batch is not None: return self.__n_batch\n",
    "        batch = tf.split(self.pt, [1, 2], -1)[0]\n",
    "        self.__n_batch = int(tf.reduce_max(batch)) - int(tf.reduce_min(batch)) + 1\n",
    "        return self.__n_batch\n",
    "\n",
    "\n",
    "def gaussian_kernel(\n",
    "        kernel_size: int,\n",
    "        sigma: Union[None, float] = None\n",
    ") -> tf.Tensor:\n",
    "    if kernel_size == 0 and (sigma is None or sigma < 0.8):\n",
    "        if sigma is None:\n",
    "            raise ValueError('need sigma parameter when the kernel size is 0')\n",
    "        raise ValueError('minimum kernel need to be size of 3 --> sigma > 0.8')\n",
    "\n",
    "    if kernel_size == 0:\n",
    "        kernel_size = ((((sigma - 0.8) / 0.3) + 1) * 2) + 1\n",
    "        kernel_size = kernel_size + 1 if (kernel_size % 2) == 0 else kernel_size\n",
    "\n",
    "    assert kernel_size % 2 != 0 and kernel_size > 2\n",
    "\n",
    "    if sigma is None:\n",
    "        sigma = 0.3 * ((kernel_size - 1) * 0.5 - 1) + 0.8\n",
    "\n",
    "    ax = tf.range(-kernel_size // 2 + 1.0, kernel_size // 2 + 1.0)\n",
    "    xx, yy = tf.meshgrid(ax, ax)\n",
    "    normal = 1 / (2.0 * PI * (sigma ** 2))\n",
    "    kernel = tf.exp(\n",
    "        -((xx ** 2) + (yy ** 2)) / (2.0 * (sigma ** 2))\n",
    "    ) * normal\n",
    "    return kernel / tf.reduce_sum(kernel)\n",
    "\n",
    "\n",
    "def make_neighborhood2D(\n",
    "        init_cords: tf.Tensor,\n",
    "        con: int = 3,\n",
    "        origin_shape: Union[None, tuple, list, tf.TensorShape] = None\n",
    ") -> tf.Tensor:\n",
    "    if not isinstance(init_cords, tf.Tensor): raise TypeError(\"cords need to be of type Tensor\")\n",
    "    B, ndim = init_cords.get_shape()\n",
    "    con = int(con)\n",
    "    assert ndim == 4\n",
    "\n",
    "    ax = tf.range(-con // 2 + 1, (con // 2) + 1, dtype=tf.int64)\n",
    "\n",
    "    con_kernel = tf.stack(tf.meshgrid(ax, ax)[::-1], axis=-1)\n",
    "\n",
    "    con_kernel = tf.reshape(con_kernel, shape=(1, con ** 2, 2))\n",
    "\n",
    "    b, yx, d = tf.split(init_cords, [1, 2, 1], axis=1)\n",
    "    yx = yx[:, tf.newaxis, ...]\n",
    "\n",
    "    yx = yx + con_kernel\n",
    "\n",
    "    b = tf.repeat(b[:, tf.newaxis, ...], repeats=con ** 2, axis=1)\n",
    "    d = tf.repeat(d[:, tf.newaxis, ...], repeats=con ** 2, axis=1)\n",
    "\n",
    "    neighbor = tf.concat((b, yx, d), axis=-1)\n",
    "    if origin_shape is None:\n",
    "        return neighbor\n",
    "\n",
    "    assert len(origin_shape) == 4\n",
    "    neighbor = neighbor + 1\n",
    "    b, y, x, d = tf.unstack(neighbor, num=4, axis=-1)\n",
    "\n",
    "    y_cast = tf.logical_and(tf.math.greater_equal(y, 1), tf.math.less_equal(y, origin_shape[1]))\n",
    "    x_cast = tf.logical_and(tf.math.greater_equal(x, 1), tf.math.less_equal(x, origin_shape[2]))\n",
    "\n",
    "    valid = tf.cast(tf.logical_and(y_cast, x_cast), dtype=tf.int32)\n",
    "    valid = tf.math.reduce_prod(valid, axis=-1)\n",
    "    cords_valid = tf.where(valid == 1)\n",
    "    neighbor = tf.gather_nd(neighbor, cords_valid) - 1\n",
    "    return neighbor\n",
    "\n",
    "\n",
    "def compute_extrema3D(\n",
    "        X: tf.Tensor,\n",
    "        threshold: Union[tf.Tensor, float, None] = None,\n",
    "        con: Union[tf.Tensor, int, tuple, list] = 3,\n",
    "        border_width: Union[tf.Tensor, tuple, list, None] = None,\n",
    "        epsilon: Union[tf.Tensor, float] = 1e-07\n",
    ") -> tf.Tensor:\n",
    "    if not isinstance(X, tf.Tensor): raise TypeError(\"X need to be of type Tensor\")\n",
    "    _shape = X.get_shape().as_list()\n",
    "    _n_dims = len(_shape)\n",
    "    if _n_dims != 4:\n",
    "        raise ValueError(\n",
    "            'expected the inputs to be 4D tensor with size of (None, H, W, C)'\n",
    "        )\n",
    "    b, h, w, d = tf.unstack(tf.cast(_shape, dtype=tf.int64), num=4, axis=-1)\n",
    "\n",
    "    X = tf.cast(X, dtype=tf.float32)\n",
    "\n",
    "    threshold = tf.cast(threshold, dtype=tf.float32) if threshold is not None else None\n",
    "\n",
    "    if tf.is_tensor(con):\n",
    "        con = tf.get_static_value(tf.reshape(con, shape=(-1,)))\n",
    "        con = tuple(con) if len(con) != 1 else int(con)\n",
    "\n",
    "    if isinstance(con, int):\n",
    "        con = (con, con, con)\n",
    "\n",
    "    if len(con) > 3:\n",
    "        raise ValueError('con parameter need to be int or iterable with size 3')\n",
    "\n",
    "    half_con = [c // 2 for c in con]\n",
    "\n",
    "    x_con = tf.concat((tf.expand_dims(X, -1), tf.expand_dims(X, -1) * -1.), -1)\n",
    "\n",
    "    extrema = tf.nn.max_pool3d(x_con, ksize=con, strides=[1, 1, 1], padding='VALID')\n",
    "\n",
    "    extrema_max, extrema_min = tf.unstack(extrema, 2, -1)\n",
    "    extrema_min = extrema_min * -1.\n",
    "\n",
    "    compare_array = tf.slice(X, [0, *half_con], [b, h - 2 * half_con[0], w - 2 * half_con[1], d - 2 * half_con[2]])\n",
    "\n",
    "    def _equal_with_epsilon(arr):\n",
    "        return tf.logical_and(\n",
    "            tf.math.greater_equal(arr, compare_array - epsilon),\n",
    "            tf.math.less_equal(arr, compare_array + epsilon)\n",
    "        )\n",
    "\n",
    "    extrema_cond = tf.logical_or(\n",
    "        _equal_with_epsilon(extrema_max),\n",
    "        _equal_with_epsilon(extrema_min)\n",
    "    )\n",
    "    if threshold is not None:\n",
    "        extrema_cond = tf.logical_and(extrema_cond, tf.math.greater(tf.abs(compare_array), threshold))\n",
    "\n",
    "    byxd = tf.where(extrema_cond)\n",
    "\n",
    "    byxd = byxd + tf.constant([[0] + half_con], dtype=tf.int64)\n",
    "\n",
    "    if border_width is not None:\n",
    "        if tf.is_tensor(border_width):\n",
    "            border_width = tf.get_static_value(tf.reshape(border_width, shape=(-1,)))\n",
    "            border_width = tuple(border_width)\n",
    "        if len(border_width) != 3:\n",
    "            raise ValueError('border_width need to be with len of 3')\n",
    "        cb, cy, cx, cd = tf.unstack(byxd, num=4, axis=-1)\n",
    "        by, bx, bd = tf.unstack(tf.cast(border_width, dtype=tf.int64), num=3)\n",
    "        y_cond = tf.logical_and(tf.math.greater_equal(cy, by), tf.math.less_equal(cy, h - by))\n",
    "        x_cond = tf.logical_and(tf.math.greater_equal(cx, bx), tf.math.less_equal(cx, w - bx))\n",
    "        d_cond = tf.logical_and(tf.math.greater_equal(cd, bd), tf.math.less_equal(cd, d - bd))\n",
    "\n",
    "        casted_ = tf.logical_and(tf.logical_and(y_cond, x_cond), d_cond)\n",
    "        byxd = tf.boolean_mask(byxd, casted_)\n",
    "\n",
    "    return byxd\n",
    "\n",
    "\n",
    "def compute_central_gradient3D(\n",
    "        X: tf.Tensor\n",
    ") -> tf.Tensor:\n",
    "    if not isinstance(X, tf.Tensor): raise TypeError(\"X need to be of type Tensor\")\n",
    "    _shape = X.get_shape().as_list()\n",
    "    _n_dims = len(_shape)\n",
    "    if _n_dims != 4:\n",
    "        raise ValueError(\n",
    "            'expected the inputs to be 4D tensor with size of (None, H, W, C)'\n",
    "        )\n",
    "\n",
    "    X = tf.cast(X, dtype=tf.float32)\n",
    "\n",
    "    kx = tf.constant([[0.0, 0.0, 0.0], [-1.0, 0.0, 1.0], [0.0, 0.0, 0.0]], dtype=tf.float32)\n",
    "    kx = tf.pad(\n",
    "        tf.reshape(kx, shape=(3, 3, 1, 1, 1)),\n",
    "        paddings=tf.constant([[0, 0], [0, 0], [1, 1], [0, 0], [0, 0]]),\n",
    "        constant_values=0.0\n",
    "    )\n",
    "    ky = tf.constant([[0.0, -1.0, 0.0], [0.0, 0.0, 0.0], [0.0, 1.0, 0.0]], dtype=tf.float32)\n",
    "    ky = tf.pad(\n",
    "        tf.reshape(ky, shape=(3, 3, 1, 1, 1)),\n",
    "        paddings=tf.constant([[0, 0], [0, 0], [1, 1], [0, 0], [0, 0]]),\n",
    "        constant_values=0.0\n",
    "    )\n",
    "    kz = tf.zeros_like(kx)\n",
    "    kz = tf.tensor_scatter_nd_update(kz, tf.constant([[1, 1, 0, 0, 0], [1, 1, 2, 0, 0]]), tf.constant([-1.0, 1.0]))\n",
    "\n",
    "    kernels_dx = tf.concat((kx, ky, kz), axis=-1)\n",
    "\n",
    "    X = tf.expand_dims(X, axis=-1)\n",
    "    grad = tf.nn.convolution(X, kernels_dx, padding='VALID') * 0.5\n",
    "    return grad\n",
    "\n",
    "\n",
    "def compute_hessian_3D(\n",
    "        X: tf.Tensor\n",
    ") -> tf.Tensor:\n",
    "    if not isinstance(X, tf.Tensor): raise TypeError(\"X need to be of type Tensor\")\n",
    "    _shape = X.get_shape().as_list()\n",
    "    _n_dims = len(_shape)\n",
    "    if _n_dims != 4:\n",
    "        raise ValueError(\n",
    "            'expected the inputs to be 4D tensor with size of (None, H, W, C)'\n",
    "        )\n",
    "\n",
    "    X = tf.cast(X, dtype=tf.float32)\n",
    "\n",
    "    dxx = tf.constant([[0.0, 0.0, 0.0], [1.0, -2.0, 1.0], [0.0, 0.0, 0.0]], dtype=tf.float32)\n",
    "    dxx = tf.pad(\n",
    "        tf.reshape(dxx, shape=(3, 3, 1, 1, 1)),\n",
    "        paddings=tf.constant([[0, 0], [0, 0], [1, 1], [0, 0], [0, 0]]),\n",
    "        constant_values=0.0\n",
    "    )\n",
    "    dyy = tf.constant([[0.0, 1.0, 0.0], [0.0, -2.0, 0.0], [0.0, 1.0, 0.0]], dtype=tf.float32)\n",
    "    dyy = tf.pad(\n",
    "        tf.reshape(dyy, shape=(3, 3, 1, 1, 1)),\n",
    "        paddings=tf.constant([[0, 0], [0, 0], [1, 1], [0, 0], [0, 0]]),\n",
    "        constant_values=0.0\n",
    "    )\n",
    "    dzz = tf.zeros_like(dxx)\n",
    "    dzz = tf.tensor_scatter_nd_update(\n",
    "        dzz, tf.constant([[1, 1, 0, 0, 0], [1, 1, 1, 0, 0], [1, 1, 2, 0, 0]]), tf.constant([1.0, -2.0, 1.0])\n",
    "    )\n",
    "\n",
    "    kww = tf.concat((dxx, dyy, dzz), axis=-1)\n",
    "\n",
    "    dxy = tf.constant([[1.0, 0.0, -1.0], [0.0, 0.0, 0.0], [-1.0, 0.0, 1.0]], dtype=tf.float32)\n",
    "    dxy = tf.pad(\n",
    "        tf.reshape(dxy, shape=(3, 3, 1, 1, 1)),\n",
    "        paddings=tf.constant([[0, 0], [0, 0], [1, 1], [0, 0], [0, 0]]),\n",
    "        constant_values=0.0\n",
    "    )\n",
    "\n",
    "    dxz = tf.zeros_like(dxy)\n",
    "    dxz = tf.tensor_scatter_nd_update(\n",
    "        dxz,\n",
    "        tf.constant([[1, 0, 0, 0, 0], [1, 2, 2, 0, 0], [1, 0, 2, 0, 0], [1, 2, 0, 0, 0]]),\n",
    "        tf.constant([1.0, 1.0, -1.0, -1.0])\n",
    "    )\n",
    "\n",
    "    dyz = tf.zeros_like(dxy)\n",
    "    dyz = tf.tensor_scatter_nd_update(\n",
    "        dyz,\n",
    "        tf.constant([[0, 1, 0, 0, 0], [2, 1, 2, 0, 0], [0, 1, 2, 0, 0], [2, 1, 0, 0, 0]]),\n",
    "        tf.constant([1.0, 1.0, -1.0, -1.0])\n",
    "    )\n",
    "\n",
    "    kws = tf.concat((dxy, dyz, dxz), axis=-1)\n",
    "\n",
    "    X = tf.expand_dims(X, axis=-1)\n",
    "\n",
    "    dFww = tf.nn.convolution(X, kww, padding='VALID')\n",
    "\n",
    "    dFws = tf.nn.convolution(X, kws, padding='VALID') * 0.25\n",
    "\n",
    "    dxx, dyy, dzz = tf.unstack(dFww, 3, axis=-1)\n",
    "    dxy, dyz, dxz = tf.unstack(dFws, 3, axis=-1)\n",
    "    hessian_mat = tf.stack(\n",
    "        (\n",
    "            tf.stack((dxx, dxy, dxz), axis=-1),\n",
    "            tf.stack((dxy, dyy, dyz), axis=-1),\n",
    "            tf.stack((dxz, dyz, dzz), axis=-1)\n",
    "        ), axis=-1\n",
    "    )\n",
    "    return hessian_mat\n",
    "\n",
    "\n",
    "def compute_mag_ori(\n",
    "        gss: tf.Tensor\n",
    ") -> tuple[tf.Tensor, tf.Tensor]:\n",
    "    if not isinstance(gss, tf.Tensor): raise TypeError(\"gss need to be of type Tensor\")\n",
    "    kx = tf.constant([[0.0, 0.0, 0.0], [-1.0, 0.0, 1.0], [0.0, 0.0, 0.0]], shape=(3, 3, 1, 1, 1), dtype=tf.float32)\n",
    "    ky = tf.constant([[0.0, -1.0, 0.0], [0.0, 0.0, 0.0], [0.0, 1.0, 0.0]], shape=(3, 3, 1, 1, 1), dtype=tf.float32)\n",
    "    gradient_kernel = tf.concat((kx, ky), axis=-1)\n",
    "\n",
    "    gradient = tf.nn.convolution(tf.expand_dims(gss, -1), gradient_kernel, padding='VALID')\n",
    "    dx, dy = tf.unstack(gradient, 2, axis=-1)\n",
    "\n",
    "    magnitude = tf.math.sqrt(dx * dx + dy * dy)\n",
    "    orientation = tf.math.atan2(dy, dx) * (180.0 / PI)\n",
    "\n",
    "    return magnitude, orientation\n",
    "\n",
    "\n",
    "def load_image(\n",
    "        name: str,\n",
    "        color_mode: str = 'grayscale'\n",
    ") -> tf.Tensor:\n",
    "    im = tf.keras.utils.load_img(name, color_mode=color_mode)\n",
    "    im = tf.convert_to_tensor(tf.keras.utils.img_to_array(im), dtype=tf.float32)\n",
    "    return im[tf.newaxis, ...]\n",
    "\n",
    "\n",
    "def templet_matching_TF(\n",
    "        scr_kp: KT,\n",
    "        dst_kp: KT,\n",
    "        scr_dsc: tf.Tensor,\n",
    "        dst_dsc: tf.Tensor,\n",
    "        ratio_threshold: float = 0.7\n",
    ") -> tuple[Union[list[tf.Tensor], tf.Tensor], Union[list[tf.Tensor], tf.Tensor]]:\n",
    "    if not isinstance(scr_kp, KeyPoints) or not isinstance(dst_kp, KeyPoints):\n",
    "        raise TypeError('Key points need to be of type \"KeyPoints\"')\n",
    "    if not isinstance(scr_dsc, tf.Tensor) or not isinstance(dst_dsc, tf.Tensor):\n",
    "        raise TypeError('descriptors need to be of type \"Tensor\"')\n",
    "    if scr_kp.n_batches() > 1: raise ValueError(\"number of batches in the templet key points > 1\")\n",
    "    if dst_kp.n_batches() > 1:\n",
    "        dst_kp_, dst_dsc_ = dst_kp.partition_by_batch(descriptors=dst_dsc)\n",
    "        out_src_pt = []\n",
    "        out_dst_pt = []\n",
    "        for kpt, dsc in zip(dst_kp_, dst_dsc_):\n",
    "            src_pt_, dst_pt_ = templet_matching_TF(scr_kp, kpt, scr_dsc, dsc)\n",
    "            out_src_pt.append(src_pt_)\n",
    "            out_dst_pt.append(dst_pt_)\n",
    "        return out_src_pt, out_dst_pt\n",
    "\n",
    "    diff = tf.transpose(tf.expand_dims(scr_dsc, 0), (0, 2, 1)) - tf.expand_dims(dst_dsc, -1)\n",
    "    diff = tf.norm(diff, ord='euclidean', axis=1)\n",
    "    diff = tf.transpose(diff, (1, 0))\n",
    "\n",
    "    _, indices = tf.math.top_k(-diff, k=2)\n",
    "    values = tf.gather(diff, indices, batch_dims=-1)\n",
    "\n",
    "    m_dist, n_dist = tf.unstack(values, 2, -1)\n",
    "    mask = tf.where(m_dist < ratio_threshold * n_dist, True, False)\n",
    "\n",
    "    des_index = tf.boolean_mask(tf.unstack(indices, 2, -1)[0], mask)\n",
    "    scr_index = tf.cast(tf.squeeze(tf.where(mask)), tf.int32)\n",
    "\n",
    "    src_pt = tf.gather(scr_kp.to_image_size().pt, scr_index)\n",
    "    dst_pt = tf.gather(dst_kp.to_image_size().pt, des_index)\n",
    "    return src_pt, dst_pt\n",
    "\n",
    "\n",
    "def templet_matching_CV2(\n",
    "        scr_kp: KT,\n",
    "        dst_kp: KT,\n",
    "        scr_dsc: tf.Tensor,\n",
    "        dst_dsc: tf.Tensor,\n",
    "        ratio_threshold: float = 0.7\n",
    ") -> tuple[tf.Tensor, tf.Tensor]:\n",
    "    if not isinstance(scr_kp, KeyPoints) or not isinstance(dst_kp, KeyPoints):\n",
    "        raise TypeError('Key points need to be of type \"KeyPoints\"')\n",
    "    if not isinstance(scr_dsc, tf.Tensor) or not isinstance(dst_dsc, tf.Tensor):\n",
    "        raise TypeError('descriptors need to be of type \"Tensor\"')\n",
    "    if scr_kp.n_batches() > 1: raise ValueError(\"number of batches in the templet key points > 1\")\n",
    "    if dst_kp.n_batches() > 1:\n",
    "        dst_kp_, dst_dsc_ = dst_kp.partition_by_batch(descriptors=dst_dsc)\n",
    "        out_src_pt = []\n",
    "        out_dst_pt = []\n",
    "        for kpt, dsc in zip(dst_kp_, dst_dsc_):\n",
    "            src_pt_, dst_pt_ = templet_matching_CV2(scr_kp, kpt, scr_dsc, dsc)\n",
    "            out_src_pt.append(src_pt_)\n",
    "            out_dst_pt.append(dst_pt_)\n",
    "        return out_src_pt, out_dst_pt\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(dict(algorithm=0, trees=5), dict(checks=50))\n",
    "\n",
    "    scr_dsc = scr_dsc.numpy()\n",
    "    dst_dsc = dst_dsc.numpy()\n",
    "\n",
    "    matches = flann.knnMatch(scr_dsc, dst_dsc, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_threshold * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    good.sort(key=lambda m: m.distance)\n",
    "\n",
    "    src_index = [m.queryIdx for m in good]\n",
    "    dst_index = [m.trainIdx for m in good]\n",
    "\n",
    "    src_pt = tf.gather(scr_kp.to_image_size().pt, tf.constant(src_index, dtype=tf.int32))\n",
    "    dst_pt = tf.gather(dst_kp.to_image_size().pt, tf.constant(dst_index, dtype=tf.int32))\n",
    "    return src_pt, dst_pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend\n",
    "\n",
    "# https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\n",
    "\n",
    "backend.set_floatx('float32')\n",
    "linalg_ops = tf.linalg\n",
    "math_ops = tf.math\n",
    "image_ops = tf.image\n",
    "\n",
    "\n",
    "class SIFT:\n",
    "    def __init__(\n",
    "            self,\n",
    "            sigma: float = 1.6,\n",
    "            assume_blur_sigma: float = 0.5,\n",
    "            n_intervals: int = 3,\n",
    "            n_octaves: Union[int, None] = None,\n",
    "            border_width: int = 5,\n",
    "            convergence_iter: int = 5\n",
    "    ):\n",
    "        self.sigma = sigma\n",
    "        self.assume_blur_sigma = assume_blur_sigma\n",
    "        self.n_intervals = n_intervals\n",
    "        self.n_octaves = n_octaves\n",
    "        self.border_width = border_width\n",
    "        self.convergence_N = convergence_iter\n",
    "        self.octave_pyramid: list[Octave] = []\n",
    "        self.templet_capture: Union[None, list[KeyPoints, tf.Tensor]] = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'S(sigma)={self.sigma}, AssumeBlurS={self.assume_blur_sigma}, ScalesPerOctave={self.n_intervals + 3}, NumOfOctaves={self.n_octaves}'\n",
    "\n",
    "    def __init_graph(\n",
    "            self,\n",
    "            inputs: tf.Tensor\n",
    "    ) -> tuple[tf.Tensor, list[tf.Tensor]]:\n",
    "        if not isinstance(inputs, tf.Tensor): raise ValueError('Input image need to be of type Tensor')\n",
    "\n",
    "        _shape = inputs.get_shape().as_list()\n",
    "        if len(_shape) != 4 or _shape[-1] != 1:\n",
    "            raise ValueError('expected the inputs to be grayscale images with size of (None, h, w, 1)')\n",
    "\n",
    "        inputs = tf.cast(inputs, dtype=tf.float32)\n",
    "        _, h_, w_, _ = _shape\n",
    "\n",
    "        kernels = self.__pyramid_kernels()\n",
    "\n",
    "        min_shape = int(kernels[-1].get_shape()[0])\n",
    "        s_ = tf.cast(min([h_ * 2, w_ * 2]), dtype=tf.float32)\n",
    "        diff = math_ops.log(s_)\n",
    "        if min_shape > 1: diff = diff - math_ops.log(tf.cast(min_shape, dtype=tf.float32))\n",
    "        max_n_octaves = int(tf.round(diff / math_ops.log(2.0)) + 1)\n",
    "\n",
    "        if self.n_octaves is not None and max_n_octaves > self.n_octaves: max_n_octaves = self.n_octaves\n",
    "        self.n_octaves = max_n_octaves\n",
    "        return inputs, kernels\n",
    "\n",
    "    def __pyramid_kernels(\n",
    "            self\n",
    "    ) -> list[tf.Tensor]:\n",
    "        delta_sigma = (self.sigma ** 2) - ((2 * self.assume_blur_sigma) ** 2)\n",
    "        delta_sigma = math_ops.sqrt(tf.maximum(delta_sigma, 0.64))\n",
    "\n",
    "        base_kernel = gaussian_kernel(kernel_size=0, sigma=delta_sigma)\n",
    "        base_kernel = tf.expand_dims(tf.expand_dims(base_kernel, axis=-1), axis=-1)\n",
    "\n",
    "        images_per_octaves = self.n_intervals + 3\n",
    "        K = 2 ** (1 / self.n_intervals)\n",
    "        K = tf.cast(K, dtype=tf.float32)\n",
    "\n",
    "        kernels = [base_kernel]\n",
    "\n",
    "        for i in range(1, images_per_octaves):\n",
    "            s_prev = self.sigma * (K ** (i - 1))\n",
    "            s = math_ops.sqrt((K * s_prev) ** 2 - s_prev ** 2)\n",
    "            kernel_ = gaussian_kernel(kernel_size=0, sigma=s)\n",
    "            kernels.append(tf.expand_dims(tf.expand_dims(kernel_, axis=-1), axis=-1))\n",
    "        return kernels\n",
    "\n",
    "    def __assign_descriptors(\n",
    "            self,\n",
    "            descriptors: tf.Tensor,\n",
    "            bins: tf.Tensor,\n",
    "            magnitude: tf.Tensor\n",
    "    ) -> tf.Tensor:\n",
    "        N_bins, window_width = 8, 4\n",
    "        _, y, x, _ = tf.unstack(bins, 4, -1)\n",
    "        mask = tf.where((y > -1) & (y < window_width) & (x > -1) & (x < window_width), True, False)\n",
    "        magnitude = tf.boolean_mask(magnitude, mask)\n",
    "\n",
    "        b, y, x, z = tf.unstack(tf.boolean_mask(bins, mask), 4, -1)\n",
    "\n",
    "        while tf.reduce_min(z) < 0:\n",
    "            z = tf.where(z < 0, z + N_bins, z)\n",
    "\n",
    "        while tf.reduce_max(z) >= N_bins:\n",
    "            z = tf.where(z >= N_bins, z - N_bins, z)\n",
    "\n",
    "        bin_floor = [b] + [tf.round(tf.floor(h)) for h in [y, x, z]]\n",
    "        bin_frac = [tf.reshape(h - hf, (-1,)) for h, hf in zip([y, x, z], bin_floor[1:])]\n",
    "\n",
    "        y, x, z = bin_frac\n",
    "\n",
    "        _C0 = magnitude * (1 - y)\n",
    "        _C1 = magnitude * y\n",
    "\n",
    "        # interpolation in x direction\n",
    "        _C00 = _C0 * (1 - x)\n",
    "        _C01 = _C0 * x\n",
    "\n",
    "        _C10 = _C1 * (1 - x)\n",
    "        _C11 = _C1 * x\n",
    "\n",
    "        # interpolation in z direction\n",
    "        _C000 = _C00 * (1 - z)\n",
    "        _C001 = _C00 * z\n",
    "        _C010 = _C01 * (1 - z)\n",
    "        _C011 = _C01 * z\n",
    "        _C100 = _C10 * (1 - z)\n",
    "        _C101 = _C10 * z\n",
    "        _C110 = _C11 * (1 - z)\n",
    "        _C111 = _C11 * z\n",
    "\n",
    "        b, y, x, z = [tf.cast(c, tf.int32) for c in bin_floor]\n",
    "        descriptors = tf.tensor_scatter_nd_add(descriptors, tf.stack((b, y + 1, x + 1, z), -1), _C000)\n",
    "        descriptors = tf.tensor_scatter_nd_add(descriptors, tf.stack((b, y + 1, x + 1, (z + 1) % N_bins), -1), _C001)\n",
    "\n",
    "        descriptors = tf.tensor_scatter_nd_add(descriptors, tf.stack((b, y + 1, x + 2, z), -1), _C010)\n",
    "        descriptors = tf.tensor_scatter_nd_add(descriptors, tf.stack((b, y + 1, x + 2, (z + 1) % N_bins), -1), _C011)\n",
    "\n",
    "        descriptors = tf.tensor_scatter_nd_add(descriptors, tf.stack((b, y + 2, x + 1, z), -1), _C100)\n",
    "        descriptors = tf.tensor_scatter_nd_add(descriptors, tf.stack((b, y + 2, x + 1, (z + 1) % N_bins), -1), _C101)\n",
    "\n",
    "        descriptors = tf.tensor_scatter_nd_add(descriptors, tf.stack((b, y + 2, x + 2, z), -1), _C110)\n",
    "        descriptors = tf.tensor_scatter_nd_add(descriptors, tf.stack((b, y + 2, x + 2, (z + 1) % N_bins), -1), _C111)\n",
    "\n",
    "        return descriptors\n",
    "\n",
    "    def __descriptors_per_octave(\n",
    "            self,\n",
    "            octave: Octave,\n",
    "            key_points: KeyPoints\n",
    "    ) -> tf.Tensor:\n",
    "        scale_multiplier, window_width, N_bins, descriptor_max_value = 3, 4, 8, 0.2\n",
    "        bins_per_degree = N_bins / 360.\n",
    "        weight_multiplier = -1.0 / (0.5 * window_width * window_width)\n",
    "        descriptors = tf.zeros((key_points.shape[0], window_width + 2, window_width + 2, N_bins), tf.float32)\n",
    "\n",
    "        key_points = key_points.to_image_size()\n",
    "        unpack_oct = key_points.unpack_octave()\n",
    "\n",
    "        scale_ = tf.pad(tf.repeat(unpack_oct.scale, 2, axis=1), tf.constant([[0, 0], [1, 0]]), constant_values=1.0)\n",
    "        points = tf.round(tf.concat((key_points.pt * scale_, unpack_oct.layer), -1))\n",
    "        histogram_width = scale_multiplier * 0.5 * unpack_oct.scale * key_points.size\n",
    "        radius = tf.round(histogram_width * math_ops.sqrt(2.0) * (window_width + 1.0) * 0.5)\n",
    "\n",
    "        _, y, x, _ = tf.split(points, [1] * 4, -1)\n",
    "        radius = math_ops.minimum(\n",
    "            math_ops.minimum(octave.shape[1] - 3 - y, octave.shape[2] - 3 - x),\n",
    "            math_ops.minimum(math_ops.minimum(y, x), radius)\n",
    "        )\n",
    "        radius = tf.reshape(radius, (-1,))\n",
    "        parallel = tf.unique(radius)\n",
    "\n",
    "        indexes = tf.dynamic_partition(tf.reshape(tf.range(key_points.shape[0], dtype=tf.int32), (-1, 1)),\n",
    "                                       parallel.idx, tf.reduce_max(parallel.idx) + 1)\n",
    "\n",
    "        wrap = tf.concat((points, key_points.angle, histogram_width), -1)\n",
    "        wrap = tf.dynamic_partition(wrap, parallel.idx, parallel.y.get_shape()[0])\n",
    "\n",
    "        M = octave.magnitude\n",
    "        T = octave.orientation % 360.0\n",
    "\n",
    "        for index, wrap_i, r in zip(indexes, wrap, parallel.y):\n",
    "            points, angle, width = tf.split(wrap_i, [4, 1, 1], -1)\n",
    "            angle = 360.0 - angle\n",
    "            n = points.get_shape()[0]\n",
    "            cos = math_ops.cos((PI / 180) * angle)\n",
    "            sin = math_ops.sin((PI / 180) * angle)\n",
    "\n",
    "            neighbor = make_neighborhood2D(tf.constant([[0, 0, 0, 0]], dtype=tf.int64), con=(r * 2) + 1)\n",
    "            block = tf.expand_dims(tf.cast(points, tf.int64), axis=1) + neighbor\n",
    "\n",
    "            neighbor = tf.cast(tf.repeat(tf.split(neighbor, [1, 2, 1], -1)[1], n, 0), tf.float32)\n",
    "            y, x = tf.unstack(neighbor, 2, -1)\n",
    "            b = tf.cast(tf.ones(y.get_shape(), dtype=tf.int32) * index, tf.float32)\n",
    "\n",
    "            rotate = [(- (x * sin) + (y * cos)) / width, ((x * cos) + (y * sin)) / width]\n",
    "            weight = tf.reshape(math_ops.exp(weight_multiplier * (rotate[0] ** 2 + rotate[1] ** 2)), (-1,))\n",
    "\n",
    "            magnitude = tf.gather_nd(M, tf.reshape(block, (-1, 4))) * weight\n",
    "            orientation = tf.reshape(tf.gather_nd(T, tf.reshape(block, (-1, 4))), (n, -1))\n",
    "            orientation = ((orientation - angle) * bins_per_degree)\n",
    "\n",
    "            hist_bin = [b] + [rot + 0.5 * window_width - 0.5 for rot in rotate] + [orientation]\n",
    "            hist_bin = tf.reshape(tf.stack(hist_bin, -1), (-1, 4))\n",
    "\n",
    "            descriptors = self.__assign_descriptors(descriptors, hist_bin, magnitude)\n",
    "\n",
    "        descriptors = tf.slice(descriptors, [0, 1, 1, 0], [key_points.shape[0], window_width, window_width, N_bins])\n",
    "        descriptors = tf.reshape(descriptors, (key_points.shape[0], -1))\n",
    "\n",
    "        threshold = tf.norm(descriptors, ord=2, axis=1, keepdims=True) * descriptor_max_value\n",
    "        threshold = tf.repeat(threshold, N_bins * window_width * window_width, 1)\n",
    "        descriptors = tf.where(descriptors > threshold, threshold, descriptors)\n",
    "        descriptors = descriptors / tf.maximum(tf.norm(descriptors, ord=2, axis=1, keepdims=True), 1e-7)\n",
    "        descriptors = tf.round(descriptors * 512)\n",
    "        descriptors = tf.maximum(descriptors, 0)\n",
    "        descriptors = tf.minimum(descriptors, 255)\n",
    "        return descriptors\n",
    "\n",
    "    def localize_extrema(\n",
    "            self,\n",
    "            octave: Octave\n",
    "    ) -> KeyPoints:\n",
    "        if not isinstance(octave, Octave): raise ValueError('octave need to by of type \"Octave\"')\n",
    "        dim = octave.shape[-1]\n",
    "        con, extrema_offset, contrast_threshold, eigen_ration = 3, 0.5, 0.03, 10\n",
    "        octave_index = octave.index\n",
    "\n",
    "        \"\"\"Extract all the extrema point in the octave scale space\"\"\"\n",
    "        # D(batch, y, x, s)\n",
    "        dog = math_ops.subtract(tf.split(octave.gss, [1, dim - 1], -1)[1],\n",
    "                                tf.split(octave.gss, [dim - 1, 1], -1)[0])\n",
    "        dog_shape = dog.get_shape().as_list()\n",
    "\n",
    "        # e = (batch, y, x, s) (local extrema)\n",
    "        border_width = self.border_width - 2\n",
    "        extrema = compute_extrema3D(tf.round(dog), con=con, border_width=[border_width, border_width, 0])\n",
    "\n",
    "        dog = dog / 255.0\n",
    "\n",
    "        \"\"\"Compute the key points conditions for all the image\"\"\"\n",
    "        # DD / Dx\n",
    "        grad = compute_central_gradient3D(dog)\n",
    "        grad = tf.expand_dims(grad, -1)\n",
    "\n",
    "        # D^2D / Dx^2\n",
    "        hess = compute_hessian_3D(dog)\n",
    "\n",
    "        # X' = - (D^2D / Dx^2) * (DD / Dx)\n",
    "        extrema_update = - linalg_ops.lstsq(hess, grad, l2_regularizer=0.0, fast=False)\n",
    "        extrema_update = tf.squeeze(extrema_update, axis=-1)\n",
    "\n",
    "        # (DD / Dx) * X'\n",
    "        dot_ = linalg_ops.matmul(tf.expand_dims(extrema_update, 4), grad)\n",
    "        dot_ = tf.squeeze(tf.squeeze(dot_, -1), -1)\n",
    "\n",
    "        mid_cube_values = tf.slice(dog, [0, 1, 1, 1],\n",
    "                                   [dog_shape[0], dog_shape[1] - 2, dog_shape[2] - 2, dog_shape[3] - 2])\n",
    "\n",
    "        # D(X') = D + 0.5 * (DD / Dx) * X'\n",
    "        update_response = mid_cube_values + 0.5 * dot_\n",
    "\n",
    "        hess_shape = hess.get_shape().as_list()\n",
    "        # H[[Dxx, Dxy], [Dyx, Dyy]]\n",
    "        hess_xy = tf.slice(hess, [0, 0, 0, 0, 0, 0], [*hess_shape[:-2], 2, 2])\n",
    "        # Dxx + Dyy\n",
    "        hess_xy_trace = linalg_ops.trace(hess_xy)\n",
    "        # Dxx * Dyy - Dxy * Dyx\n",
    "        hess_xy_det = linalg_ops.det(hess_xy)\n",
    "\n",
    "        # |X'| <= 0.5\n",
    "        # (X' is larger than 0.5 in any dimension, means that the extreme lies closer to a different sample point)\n",
    "        kp_cond1 = math_ops.less_equal(math_ops.reduce_max(math_ops.abs(extrema_update), axis=-1), extrema_offset)\n",
    "\n",
    "        # |D(X')| >= 0.03 (threshold on minimum contrast)\n",
    "        kp_cond2 = math_ops.greater_equal(math_ops.abs(update_response), contrast_threshold)\n",
    "\n",
    "        # (Dxx + Dyy) ^ 2 / Dxx * Dyy - Dxy * Dyx < (r + 1) ^ 2 / r\n",
    "        # ---> ((Dxx + Dyy) ^ 2) * r < (Dxx * Dyy - Dxy * Dyx) * ((r + 1) ^ 2)\n",
    "        # (threshold on ratio of principal curvatures)\n",
    "        kp_cond3 = math_ops.logical_and(\n",
    "            eigen_ration * (hess_xy_trace ** 2) < ((eigen_ration + 1) ** 2) * hess_xy_det, hess_xy_det != 0\n",
    "        )\n",
    "        cond = tf.where(kp_cond1 & kp_cond2 & kp_cond3, True, False)\n",
    "\n",
    "        kp_cond4 = tf.scatter_nd(extrema, tf.ones((extrema.shape[0],), dtype=tf.bool), dog_shape)\n",
    "        kp_cond4 = tf.slice(kp_cond4, [0, 1, 1, 1],\n",
    "                            [dog_shape[0], dog_shape[1] - 2, dog_shape[2] - 2, dog_shape[3] - 2])\n",
    "\n",
    "        \"\"\"Localize the extrema points\"\"\"\n",
    "        sure_key_points = math_ops.logical_and(cond, kp_cond4)\n",
    "        attempts = math_ops.logical_and(kp_cond4, ~sure_key_points)\n",
    "\n",
    "        shape_ = sure_key_points.get_shape().as_list()\n",
    "\n",
    "        for _ in range(self.convergence_N):\n",
    "            attempts_cords = tf.where(attempts)\n",
    "            if attempts_cords.shape[0] == 0: break\n",
    "            # if ist only one point the shape will bw (4, )\n",
    "            attempts_cords = tf.reshape(attempts_cords, (-1, 4))\n",
    "            attempts_update = tf.gather_nd(extrema_update, attempts_cords)\n",
    "\n",
    "            ex, ey, ez = tf.unstack(attempts_update, num=3, axis=-1)\n",
    "            cd, cy, cx, cz = tf.unstack(tf.cast(attempts_cords, tf.float32), num=4, axis=1)\n",
    "            attempts_next = [cd, cy + ey, cx + ex, cz + ez]\n",
    "\n",
    "            # check that the new cords will lie within the image shape\n",
    "            cond_next = tf.where(\n",
    "                (attempts_next[1] >= 0) & (attempts_next[1] < shape_[1]) & (attempts_next[2] > 0) & (\n",
    "                        attempts_next[2] < shape_[2]) & (attempts_next[3] > 0) & (\n",
    "                        attempts_next[3] < shape_[3]))\n",
    "\n",
    "            attempts_next = tf.stack(attempts_next, -1)\n",
    "            attempts_next = tf.cast(tf.gather(attempts_next, tf.squeeze(cond_next)), dtype=tf.int64)\n",
    "            if attempts_next.shape[0] == 0: break\n",
    "            attempts_next = tf.reshape(attempts_next, (-1, 4))\n",
    "\n",
    "            attempts_mask = tf.scatter_nd(attempts_next, tf.ones((attempts_next.shape[0],), dtype=tf.bool), shape_)\n",
    "\n",
    "            # add new key points\n",
    "            new_cords = tf.where(attempts_mask & ~sure_key_points & cond)\n",
    "            sure_key_points = tf.tensor_scatter_nd_update(sure_key_points, new_cords,\n",
    "                                                          tf.ones((new_cords.shape[0],), dtype=tf.bool))\n",
    "            # next points\n",
    "            attempts = math_ops.logical_and(attempts_mask, ~sure_key_points)\n",
    "\n",
    "        \"\"\"Construct the key points\"\"\"\n",
    "        cords = tf.where(sure_key_points)\n",
    "        if cords.shape[0] == 0: return KeyPoints()\n",
    "        kp_cords = cords + tf.constant([[0, 1, 1, 1]], dtype=tf.int64)\n",
    "\n",
    "        # X' = - (D^2D / Dx^2) * (DD / Dx)\n",
    "        extrema_update = tf.gather_nd(extrema_update, cords)\n",
    "        octave_index = tf.cast(octave_index, dtype=tf.float32)\n",
    "\n",
    "        # x', y', s'\n",
    "        ex, ey, ez = tf.unstack(extrema_update, num=3, axis=1)\n",
    "\n",
    "        # batch, y, x, s\n",
    "        cd, cy, cx, cz = tf.unstack(tf.cast(kp_cords, tf.float32), num=4, axis=1)\n",
    "\n",
    "        # pt = (batch, y = (y + y') * (1 << octave), (x + x') * (1 << octave), s) points in size of octave 0\n",
    "        kp_pt = tf.stack(\n",
    "            (cd, (cy + ey) * (2 ** octave_index), (cx + ex) * (2 ** octave_index), cz), axis=-1\n",
    "        )\n",
    "        # octave = octave_index + s * (1 << 8) + round((s' + 0.5) * 255) * (1 << 16)\n",
    "        kp_octave = octave_index + cz * (2 ** 8) + tf.round((ez + 0.5) * 255.0) * (2 ** 16)\n",
    "\n",
    "        # size = (sigma << ((s + s') / sn)) << (octave_index + 1)\n",
    "        kp_size = self.sigma * (2 ** ((cz + ez) / (dim - 3))) * (2 ** (octave_index + 1.0))\n",
    "\n",
    "        # D(X') = D + 0.5 * (DD / Dx) * X'\n",
    "        kp_response = math_ops.abs(tf.gather_nd(update_response, cords))\n",
    "\n",
    "        key_points = KeyPoints(\n",
    "            pt=tf.reshape(kp_pt, (-1, 4)),\n",
    "            size=tf.reshape(kp_size, (-1, 1)),\n",
    "            angle=tf.reshape(tf.ones_like(kp_size) * -1.0, (-1, 1)),\n",
    "            octave=tf.reshape(kp_octave, (-1, 1)),\n",
    "            response=tf.reshape(kp_response, (-1, 1))\n",
    "        )\n",
    "        return key_points\n",
    "\n",
    "    def orientation_assignment(\n",
    "            self,\n",
    "            octave: Octave,\n",
    "            key_points: KeyPoints\n",
    "    ) -> KeyPoints:\n",
    "        if not isinstance(octave, Octave): raise ValueError('octave need to by of type \"Octave\"')\n",
    "        if not isinstance(key_points, KeyPoints): raise ValueError('key_points need to by of type \"KeyPoints\"')\n",
    "\n",
    "        orientation_N_bins, scale_factor, radius_factor = 36, 1.5, 3\n",
    "        histogram = tf.zeros((key_points.shape[0], orientation_N_bins), dtype=tf.float32)\n",
    "\n",
    "        # scale = 1.5 * sigma  * (1 << ((s + s') / sn)\n",
    "        scale = scale_factor * key_points.size / (2 ** (octave.index + 1))\n",
    "\n",
    "        # r[N_points, ] = 3 * scale\n",
    "        radius = tf.cast(tf.round(radius_factor * scale), dtype=tf.int64)\n",
    "\n",
    "        # wf[N_points, ]\n",
    "        weight_factor = -0.5 / (scale ** 2)\n",
    "\n",
    "        # points back to octave resolution\n",
    "        _prob = 1.0 / (1 << octave.index)\n",
    "        _prob = tf.stack((tf.ones_like(_prob), _prob, _prob), axis=-1)\n",
    "        _prob = tf.squeeze(_prob)\n",
    "\n",
    "        # [batch, x + x', y + y', s] * N_points\n",
    "        region_center = tf.cast(key_points.pt * _prob, dtype=tf.int64)\n",
    "        region_center = tf.concat((region_center, tf.cast(key_points.scale_index, dtype=tf.int64)), -1)\n",
    "\n",
    "        # check that the radius in the image size\n",
    "        _, y, x, _ = tf.split(region_center, [1] * 4, -1)\n",
    "        radius = math_ops.minimum(\n",
    "            math_ops.minimum(octave.shape[1] - 3 - y, octave.shape[2] - 3 - x),\n",
    "            math_ops.minimum(math_ops.minimum(y, x), radius)\n",
    "        )\n",
    "        radius = tf.reshape(radius, (-1,))\n",
    "\n",
    "        # parallel computation\n",
    "        parallel = tf.unique(radius)\n",
    "        split_region = tf.dynamic_partition(\n",
    "            tf.concat((tf.cast(region_center, tf.float32), weight_factor), -1), parallel.idx,\n",
    "            tf.reduce_max(parallel.idx) + 1\n",
    "        )\n",
    "        index = tf.dynamic_partition(tf.reshape(tf.range(key_points.shape[0], dtype=tf.int64), (-1, 1)),\n",
    "                                     parallel.idx, tf.reduce_max(parallel.idx) + 1)\n",
    "\n",
    "        M = octave.magnitude\n",
    "        T = octave.orientation\n",
    "\n",
    "        for region_weight, r, hist_index in zip(split_region, parallel.y, index):\n",
    "            region, weight = tf.split(region_weight, [4, 1], -1)\n",
    "            if r < 1: continue\n",
    "\n",
    "            neighbor = make_neighborhood2D(tf.constant([[0, 0, 0, 0]], dtype=tf.int64), con=(r * 2) + 1)\n",
    "            block = tf.expand_dims(tf.cast(region, tf.int64), axis=1) + neighbor\n",
    "\n",
    "            magnitude = tf.gather_nd(M, tf.reshape(block, (-1, 4)))\n",
    "            orientation = tf.gather_nd(T, tf.reshape(block, (-1, 4)))\n",
    "\n",
    "            _, curr_y, curr_x, _ = tf.unstack(tf.cast(neighbor, dtype=tf.float32), 4, axis=-1)\n",
    "            weight = tf.reshape(math_ops.exp(weight * (curr_y ** 2 + curr_x ** 2)), (-1,))\n",
    "\n",
    "            hist_deg = tf.cast(tf.round(orientation * orientation_N_bins / 360.), dtype=tf.int64) % orientation_N_bins\n",
    "\n",
    "            hist_index = tf.ones(block.get_shape()[:-1], dtype=tf.int64) * tf.reshape(hist_index, (-1, 1))\n",
    "            hist_index = tf.stack((tf.reshape(hist_index, (-1,)), hist_deg), -1)\n",
    "            histogram = tf.tensor_scatter_nd_add(histogram, hist_index, weight * magnitude)\n",
    "\n",
    "        \"\"\" find peaks in the histogram \"\"\"\n",
    "        # histogram smooth\n",
    "        gaussian1D = tf.constant([1, 4, 6, 4, 1], dtype=tf.float32) / 16.0\n",
    "        gaussian1D = tf.reshape(gaussian1D, shape=(-1, 1, 1))\n",
    "\n",
    "        pad_ = tf.split(tf.expand_dims(histogram, axis=-1), [2, orientation_N_bins - 4, 2], 1)\n",
    "        pad_ = tf.concat([pad_[-1], *pad_, pad_[0]], 1)\n",
    "\n",
    "        smooth_histogram = tf.nn.convolution(pad_, gaussian1D, padding='VALID')\n",
    "        smooth_histogram = tf.squeeze(smooth_histogram, axis=-1)\n",
    "\n",
    "        orientation_max = tf.reduce_max(smooth_histogram, axis=-1)\n",
    "\n",
    "        peak = tf.nn.max_pool1d(tf.expand_dims(smooth_histogram, -1), ksize=3, padding=\"SAME\", strides=1)\n",
    "        peak = tf.squeeze(peak, -1)\n",
    "\n",
    "        value_cond = tf.repeat(tf.reshape(orientation_max, shape=(-1, 1)), repeats=36, axis=-1) * 0.8\n",
    "\n",
    "        peak = tf.where((peak == smooth_histogram) & (smooth_histogram > value_cond))\n",
    "\n",
    "        p_idx, p_deg = tf.unstack(peak, num=2, axis=-1)\n",
    "\n",
    "        # interpolate the peak position - parabola\n",
    "        kernel = tf.constant([1., 0, -1.], shape=(3, 1, 1))\n",
    "        kernel = tf.concat((kernel, tf.constant([1., -2., 1.], shape=(3, 1, 1))), -1)\n",
    "\n",
    "        pad_ = tf.split(smooth_histogram, [1, 34, 1], -1)\n",
    "        pad_ = tf.concat([pad_[-1], *pad_, pad_[0]], -1)\n",
    "\n",
    "        interp = tf.unstack(tf.nn.convolution(tf.expand_dims(pad_, -1), kernel, padding=\"VALID\"), 2, -1)\n",
    "        interp = 0.5 * (interp[0] / interp[1]) % 36\n",
    "        interp = tf.cast(p_deg, tf.float32) + tf.gather_nd(interp, peak)\n",
    "\n",
    "        orientation = 360. - interp * 360. / 36\n",
    "\n",
    "        orientation = tf.where(math_ops.abs(orientation - 360.) < 1e-7, 0.0, orientation)\n",
    "\n",
    "        wrap = key_points.as_array()\n",
    "        wrap = tf.gather(wrap, p_idx)\n",
    "        pt, size, _, oc, response = tf.split(wrap, [4, 1, 1, 1, 1], axis=-1)\n",
    "        key_points.from_array(tf.concat((pt, size, tf.reshape(orientation, (-1, 1)), oc, response), axis=-1),\n",
    "                              inplace=True)\n",
    "        key_points.relies_scale_index()\n",
    "        return key_points\n",
    "\n",
    "    def write_descriptors(\n",
    "            self,\n",
    "            key_points: KeyPoints\n",
    "    ) -> tf.Tensor:\n",
    "        if not isinstance(key_points, KeyPoints): raise ValueError('key_points need to by of type \"KeyPoints\"')\n",
    "        unpack_oct = key_points.unpack_octave()\n",
    "        parallel = tf.unique(tf.squeeze(unpack_oct.octave))\n",
    "\n",
    "        if parallel.y.get_shape()[0] == 1:\n",
    "            return self.__descriptors_per_octave(self.octave_pyramid[int(parallel.y)], key_points)\n",
    "\n",
    "        indexes = tf.dynamic_partition(tf.reshape(tf.range(key_points.shape[0], dtype=tf.int32), (-1, 1)),\n",
    "                                       parallel.idx, tf.reduce_max(parallel.idx) + 1)\n",
    "\n",
    "        split_by_oc = key_points.partition_by_index(parallel.idx)\n",
    "\n",
    "        condition_indices = []\n",
    "        partitioned_data = []\n",
    "\n",
    "        for keys, index, oc_id in zip(split_by_oc, indexes, parallel.y):\n",
    "            oc_desc = self.__descriptors_per_octave(self.octave_pyramid[int(oc_id)], keys)\n",
    "            condition_indices.append(tf.squeeze(index, -1))\n",
    "            partitioned_data.append(oc_desc)\n",
    "\n",
    "        descriptors = tf.dynamic_stitch(condition_indices, partitioned_data)\n",
    "        return descriptors\n",
    "\n",
    "    def build_pyramid(\n",
    "            self,\n",
    "            I: tf.Tensor\n",
    "    ):\n",
    "        def conv_with_pad(x: tf.Tensor, h: tf.Tensor) -> tf.Tensor:\n",
    "            k_ = h.get_shape()[0] // 2\n",
    "            x = tf.pad(x, tf.constant([[0, 0], [k_, k_], [k_, k_], [0, 0]], tf.int32), 'SYMMETRIC')\n",
    "            return tf.nn.convolution(x, h, padding='VALID')\n",
    "\n",
    "        I, kernels = self.__init_graph(I)\n",
    "        self.octave_pyramid = []\n",
    "        _, h_, w_, _ = I.get_shape()\n",
    "\n",
    "        I = image_ops.resize(I, size=[h_ * 2, w_ * 2], method='bilinear')\n",
    "        I = conv_with_pad(I, kernels[0])\n",
    "\n",
    "        size_ = [h_, w_]\n",
    "\n",
    "        for oc_id in range(self.n_octaves):\n",
    "            oc_cap = [I]\n",
    "            for kernel in kernels[1:]:\n",
    "                I = conv_with_pad(I, kernel)\n",
    "                oc_cap.append(I)\n",
    "            if oc_id < self.n_octaves - 1:\n",
    "                I = image_ops.resize(oc_cap[-3], size=size_, method='nearest')\n",
    "                size_ = [size_[0] // 2, size_[1] // 2]\n",
    "\n",
    "            gss = tf.concat(oc_cap, -1)\n",
    "            oc = Octave(oc_id, gss)\n",
    "            self.octave_pyramid.append(oc)\n",
    "\n",
    "    def keypoints_with_descriptors(\n",
    "            self,\n",
    "            inputs: tf.Tensor,\n",
    "            keep_as_templet: bool = False\n",
    "    ) -> tuple[KeyPoints, tf.Tensor]:\n",
    "        if keep_as_templet and self.templet_capture: raise Warning('prev templet will be removed')\n",
    "        self.build_pyramid(inputs)\n",
    "        key_points = KeyPoints()\n",
    "        key_points.relies_scale_index()\n",
    "\n",
    "        for oc in self.octave_pyramid:\n",
    "            oc_kp = self.localize_extrema(oc)\n",
    "            if oc_kp.shape[0] == 0: continue\n",
    "            oc_kp = self.orientation_assignment(oc, oc_kp)\n",
    "            key_points += oc_kp\n",
    "\n",
    "        descriptors = self.write_descriptors(key_points)\n",
    "        self.octave_pyramid = []\n",
    "        self.n_octaves = None\n",
    "        if keep_as_templet:\n",
    "            self.templet_capture = [key_points, descriptors]\n",
    "        return key_points, descriptors\n",
    "\n",
    "    def relies_templet(\n",
    "            self\n",
    "    ):\n",
    "        self.templet_capture = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "import cv2\n",
    "\n",
    "# matplotlib.use(\"Qt5Agg\")\n",
    "\n",
    "\n",
    "def show(\n",
    "        image: Union[np.ndarray, tf.Tensor],\n",
    "        ax: plt.Axes\n",
    "):\n",
    "    if tf.is_tensor(image):\n",
    "        image = image.numpy()\n",
    "    assert isinstance(image, np.ndarray)\n",
    "    if image.max() > 1:\n",
    "        image = image.astype('uint8')\n",
    "    if len(image.shape) == 2 or image.shape[-1] == 1:\n",
    "        ax.imshow(image, cmap='gray')\n",
    "    else:\n",
    "        ax.imshow(image)\n",
    "\n",
    "\n",
    "def show_images(\n",
    "        images: Union[np.ndarray, tf.Tensor],\n",
    "        subplot_y: Union[None, int],\n",
    "        subplot_x: Union[None, int]\n",
    "):\n",
    "    assert isinstance(images, (np.ndarray, tf.Tensor, list, tuple))\n",
    "    subplot_x = min([len(images), 4]) if subplot_x is None else subplot_x\n",
    "    subplot_y = len(images) // subplot_x if subplot_y is None else subplot_y\n",
    "\n",
    "    fig, _ = plt.subplots(subplot_x, subplot_y, subplot_kw={'xticks': [], 'yticks': []})\n",
    "    fig.subplots_adjust(wspace=0, hspace=0.05)\n",
    "\n",
    "    for i in range(min([subplot_x * subplot_y, len(images)])):\n",
    "        show(images[i], fig.axes[i])\n",
    "\n",
    "\n",
    "def show_key_points(\n",
    "        key_points: KeyPoints,\n",
    "        img: tf.Tensor\n",
    "):\n",
    "    if not isinstance(key_points, KeyPoints): raise TypeError('Key points need to be of type \"KeyPoints\"')\n",
    "    key_points = key_points.to_image_size()\n",
    "\n",
    "    if key_points.n_batches() > 1: raise ValueError(\"number of batches in the key points > 1\")\n",
    "    if not isinstance(img, tf.Tensor): raise TypeError('image need to be of type \"Tensor\"')\n",
    "\n",
    "    shape = img.get_shape().as_list()\n",
    "\n",
    "    if shape[0] > 1: raise ValueError(\"number of batches in the image > 1\")\n",
    "    if not (shape[-1] == 1 or shape[-1] == 3):\n",
    "        raise ValueError(\"image need to be with 3 channels (RGB) or gray level with one channel\")\n",
    "\n",
    "    points = tf.concat((key_points.pt, tf.zeros((key_points.shape[0], 1), tf.float32)), -1)\n",
    "    points = tf.cast(points, tf.int32)\n",
    "\n",
    "    cross = [\n",
    "        [0, -2, 0, 0],\n",
    "        [0, -1, 0, 0],\n",
    "        [0, 0, -2, 0],\n",
    "        [0, 0, -1, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 2, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 2, 0, 0]\n",
    "    ]\n",
    "\n",
    "    cross = tf.constant(cross, shape=(1, 8, 4), dtype=tf.int32)\n",
    "    neighbor = cross + tf.expand_dims(points, 1)\n",
    "    neighbor = tf.reshape(neighbor, (-1, 4))\n",
    "\n",
    "    _, y, x, _ = tf.unstack(neighbor, 4, -1)\n",
    "    mask = tf.where((y > 0) & (y < shape[1]) & (x > 0) & (x < shape[2]), True, False)\n",
    "    neighbor = tf.boolean_mask(neighbor, mask)\n",
    "\n",
    "    kpt_image = tf.zeros([*shape[:-1], 1], dtype=img.dtype)\n",
    "    kpt_image = tf.tensor_scatter_nd_add(kpt_image, neighbor, tf.ones((neighbor.get_shape()[0],), tf.float32))\n",
    "    kpt_image = tf.where(kpt_image > 0, 1, 0)\n",
    "    kpt_image = tf.concat((kpt_image * 242, kpt_image * 140, kpt_image * 40), -1)\n",
    "\n",
    "    if shape[-1] == 1:\n",
    "        img_del = tf.tensor_scatter_nd_update(img, neighbor, tf.zeros((neighbor.get_shape()[0],), tf.float32))\n",
    "        img_del = tf.cast(tf.repeat(img_del, 3, -1), tf.int32)\n",
    "    else:\n",
    "        img_del = img\n",
    "        for _ in range(3):\n",
    "            img_del = tf.tensor_scatter_nd_update(img_del, neighbor, tf.zeros((neighbor.get_shape()[0],), tf.float32))\n",
    "            neighbor = neighbor + tf.constant([0, 0, 0, 1], dtype=tf.int32)\n",
    "\n",
    "    mark = kpt_image + img_del\n",
    "    show_images(tf.cast(mark, tf.uint8), 1, 1)\n",
    "\n",
    "\n",
    "def _make_line(\n",
    "        x0: Union[tf.Tensor, int, float],\n",
    "        x1: Union[tf.Tensor, int, float],\n",
    "        y0: Union[tf.Tensor, int, float],\n",
    "        y1: Union[tf.Tensor, int, float],\n",
    "        h_limit: Union[tf.Tensor, int],\n",
    "        w_limit: Union[tf.Tensor, int]\n",
    "):\n",
    "    m = (y1 - y0) / (x1 - x0)\n",
    "    x = tf.range(x0, x1 + 1, dtype=tf.float32)\n",
    "    w = tf.sqrt(1 + tf.math.abs(m)) / 2\n",
    "    y = x * m + (x1 * y0 - x0 * y1) / (x1 - x0)\n",
    "\n",
    "    t = tf.math.ceil(w / 2)\n",
    "\n",
    "    yy = (tf.reshape(tf.math.floor(y), [-1, 1]) + tf.reshape(tf.range(-t - 1, t + 2, dtype=tf.float32), [1, -1]))\n",
    "    xx = tf.repeat(x, yy.get_shape()[1])\n",
    "\n",
    "    v = tf.clip_by_value(\n",
    "        tf.minimum(yy + 1 + 1 / 2 - tf.reshape(y, (-1, 1)), -yy + 1 + 1 / 2 + tf.reshape(y, (-1, 1))), 0, 1\n",
    "    )\n",
    "    v = tf.reshape(v, (-1,))\n",
    "    yy = tf.reshape(yy, (-1,))\n",
    "\n",
    "    limits = tf.where((yy >= 0) & (xx >= 0) & (yy < h_limit) & (xx < w_limit) & (v == 1.), True, False)\n",
    "\n",
    "    xx = tf.boolean_mask(xx, limits)\n",
    "    yy = tf.boolean_mask(yy, limits)\n",
    "    v = tf.boolean_mask(v, limits)\n",
    "\n",
    "    cords = tf.cast(tf.stack((yy, xx), -1), tf.int32)\n",
    "    cords = tf.pad(cords, [[0, 0], [1, 1]])\n",
    "    return cords, v\n",
    "\n",
    "\n",
    "def plot_matches_TF(\n",
    "        scr_img: tf.Tensor,\n",
    "        dst_img: tf.Tensor,\n",
    "        src_pt: tf.Tensor,\n",
    "        dst_pt: tf.Tensor\n",
    ") -> tf.Tensor:\n",
    "    if not isinstance(scr_img, tf.Tensor) or not isinstance(dst_img, tf.Tensor):\n",
    "        raise TypeError('descriptors need to be of type \"Tensor\"')\n",
    "    if not isinstance(src_pt, tf.Tensor) or not isinstance(dst_pt, tf.Tensor):\n",
    "        raise TypeError('points need to be of type \"Tensor\"')\n",
    "    if src_pt.get_shape()[0] != dst_pt.get_shape()[0]:\n",
    "        raise ValueError('points need to be with the same size')\n",
    "\n",
    "    _, h_scr, w_scr, c_scr = scr_img.get_shape().as_list()\n",
    "    _, h_dst, w_dst, c_dst = dst_img.get_shape().as_list()\n",
    "    if not (c_scr == 1 or c_scr == 3) or not (c_dst == 1 or c_dst == 3):\n",
    "        raise ValueError(\"images need to be with 3 channels (RGB) or gray level with one channel\")\n",
    "\n",
    "    if c_scr == 1:\n",
    "        scr_img = tf.repeat(scr_img, 3, -1)\n",
    "    if c_dst == 1:\n",
    "        dst_img = tf.repeat(dst_img, 3, -1)\n",
    "\n",
    "    h_new = max(h_scr, h_dst)\n",
    "    w_new = w_scr + w_dst\n",
    "\n",
    "    h_diff = h_new - min(h_scr, h_dst)\n",
    "    h_up = h_diff // 2\n",
    "    h_down = h_diff - h_up\n",
    "\n",
    "    if h_scr < h_dst:\n",
    "        scr_img = tf.pad(scr_img, [[0, 0], [h_up, h_down], [0, 0], [0, 0]])\n",
    "    elif h_scr > h_dst:\n",
    "        dst_img = tf.pad(dst_img, [[0, 0], [h_up, h_down], [0, 0], [0, 0]])\n",
    "\n",
    "    marked_image = tf.concat((scr_img, dst_img), 2)\n",
    "\n",
    "    src_b, src_y, src_x = tf.unstack(src_pt, 3, -1)\n",
    "    dst_b, dst_y, dst_x = tf.unstack(dst_pt, 3, -1)\n",
    "\n",
    "    if h_scr < h_dst:\n",
    "        src_y = src_y + h_up\n",
    "    elif h_scr > h_dst:\n",
    "        dst_y = dst_y + h_up\n",
    "\n",
    "    dst_x = dst_x + w_scr\n",
    "    lines = tf.zeros([*marked_image.get_shape()[:-1], 1])\n",
    "\n",
    "    for y1, x1, y2, x2 in zip(src_y, src_x, dst_y, dst_x):\n",
    "        c, val = _make_line(x1, x2, y1, y2, h_new, w_new)\n",
    "        lines = tf.tensor_scatter_nd_update(lines, c, val)\n",
    "\n",
    "    lines = tf.concat((lines * 9, lines * 121, lines * 105), -1)\n",
    "\n",
    "    marked_image = tf.where(lines > 0, lines, marked_image)\n",
    "    show_images(tf.cast(marked_image, tf.uint8), 1, 1)\n",
    "    return marked_image\n",
    "\n",
    "\n",
    "def plot_matches_CV2(\n",
    "        scr_img: tf.Tensor,\n",
    "        dst_img: tf.Tensor,\n",
    "        src_pt: tf.Tensor,\n",
    "        dst_pt: tf.Tensor\n",
    ") -> tf.Tensor:\n",
    "    if not isinstance(scr_img, tf.Tensor) or not isinstance(dst_img, tf.Tensor):\n",
    "        raise TypeError('descriptors need to be of type \"Tensor\"')\n",
    "    if not isinstance(src_pt, tf.Tensor) or not isinstance(dst_pt, tf.Tensor):\n",
    "        raise TypeError('points need to be of type \"Tensor\"')\n",
    "    if src_pt.get_shape()[0] != dst_pt.get_shape()[0]:\n",
    "        raise ValueError('points need to be with the same size')\n",
    "    _, h_scr, w_scr, c_scr = scr_img.get_shape().as_list()\n",
    "    _, h_dst, w_dst, c_dst = dst_img.get_shape().as_list()\n",
    "\n",
    "    if not (c_scr == 1 or c_scr == 3) or not (c_dst == 1 or c_dst == 3):\n",
    "        raise ValueError(\"images need to be with 3 channels (RGB) or gray level with one channel\")\n",
    "\n",
    "    if c_scr == 1:\n",
    "        scr_img = tf.repeat(scr_img, 3, -1)\n",
    "    if c_dst == 1:\n",
    "        dst_img = tf.repeat(dst_img, 3, -1)\n",
    "\n",
    "    h_new = max(h_scr, h_dst)\n",
    "    h_diff = h_new - min(h_scr, h_dst)\n",
    "    h_up = h_diff // 2\n",
    "    h_down = h_diff - h_up\n",
    "\n",
    "    if h_scr < h_dst:\n",
    "        scr_img = tf.pad(scr_img, [[0, 0], [h_up, h_down], [0, 0], [0, 0]])\n",
    "    elif h_scr > h_dst:\n",
    "        dst_img = tf.pad(dst_img, [[0, 0], [h_up, h_down], [0, 0], [0, 0]])\n",
    "\n",
    "    marked_image = tf.concat((scr_img, dst_img), 2)\n",
    "    marked_image = tf.squeeze(marked_image).numpy().astype('uint8')\n",
    "\n",
    "    _, src_y, src_x = tf.unstack(src_pt, 3, -1)\n",
    "    _, dst_y, dst_x = tf.unstack(dst_pt, 3, -1)\n",
    "\n",
    "    if h_scr < h_dst:\n",
    "        src_y = src_y + h_up\n",
    "    elif h_scr > h_dst:\n",
    "        dst_y = dst_y + h_up\n",
    "\n",
    "    dst_x = dst_x + w_scr\n",
    "    src_pt = tf.stack((src_y, src_x), -1).numpy().astype(int)\n",
    "    dst_pt = tf.stack((dst_y, dst_x), -1).numpy().astype(int)\n",
    "\n",
    "    for i in range(src_pt.shape[0]):\n",
    "        pt1 = (int(src_pt[i, 1]), int(src_pt[i, 0]))\n",
    "        pt2 = (int(dst_pt[i, 1]), int(dst_pt[i, 0]))\n",
    "        cv2.line(marked_image, pt1, pt2, (9, 121, 105))\n",
    "\n",
    "    show_images([marked_image], 1, 1)\n",
    "    return tf.constant(marked_image, shape=(1, marked_image.shape[0], marked_image.shape[1], 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# Connect to your database\n",
    "db_path = '/content/drive/MyDrive/Aerial-Template-Matching/data/Google_17.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Read the entire 'tiles' table into a pandas DataFrame\n",
    "df = pd.read_sql_query(\"SELECT * FROM tiles\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_map = cv2.imread(\"/content/drive/MyDrive/Aerial-Template-Matching/data/samples/Bing_17_sample.jpg\")\n",
    "plt.imshow(google_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extract refrence image \n",
    "image2 = load_image(\"/content/drive/MyDrive/Aerial-Template-Matching/data/samples/Bing_17_sample.jpg\")\n",
    "image2 = tf.image.resize(image2, [384, 512])  # Use TensorFlow resize\n",
    "alg = SIFT()\n",
    "kp2, desc2 = alg.keypoints_with_descriptors(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# load feature extract refrence image \n",
    "with open(\"keypoints_descriptors.pkl\", \"rb\") as f:\n",
    "    kp2, desc2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show predict\n",
    "image1 = load_image(df[\"Address\"][136].replace(\"\\\\\", \"/\"))\n",
    "kp1, desc1 = alg.keypoints_with_descriptors(image1)\n",
    "show_key_points(kp1, image1)\n",
    "\n",
    "show_key_points(kp2, image2)\n",
    "\n",
    "src_pt, dst_pt = templet_matching_CV2(kp1, kp2, desc1, desc2, ratio_threshold=0.7)\n",
    "out = plot_matches_CV2(image1, image2, src_pt, dst_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label gt show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y  = df.iloc[136][6:8]\n",
    "output_image = None\n",
    "# Assuming min_x and min_y are known or predefined values for the tile grid\n",
    "min_x, min_y = df[\"x\"].min(), df[\"y\"].min()\n",
    "tile_size = 256\n",
    "pos_x = (x - min_x) * tile_size\n",
    "pos_y = (y - min_y) * tile_size\n",
    "\n",
    "outpot = cv2.rectangle(google_map, (pos_x, pos_y),\n",
    "                             (pos_x + tile_size, pos_y + tile_size),\n",
    "                             (255, 255, 0), 7)\n",
    "\n",
    "plt.imshow(outpot, cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
